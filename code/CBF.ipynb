{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data_utils import * \n",
    "from evaluate_cbf import *\n",
    "from models import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 506, Number of items: 1674\n",
      "Training samples: 12358, Validation samples: 406, Test samples: 406\n",
      "Category features shape: (1674, 368)\n",
      "Visual features shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "train_dict = np.load('../data/training_dict.npy', allow_pickle=True).item()\n",
    "valid_dict = np.load('../data/validation_dict.npy', allow_pickle=True).item()\n",
    "test_dict = np.load('../data/testing_dict.npy', allow_pickle=True).item()\n",
    "category_features = np.load(os.path.join('../data/category_feature.npy'), allow_pickle=True).item()\n",
    "visual_features = np.load(os.path.join('../data/visual_feature.npy'), allow_pickle=True).item()\n",
    "\n",
    "# Get the number of users and items\n",
    "\n",
    "user_num = max(max(train_dict), max(valid_dict, default=-1), max(test_dict, default=-1)) + 1\n",
    "\n",
    "item_num = max(\n",
    "    max((max(items, default=-1) for items in train_dict.values()), default=-1),\n",
    "    max((max(items, default=-1) for items in valid_dict.values()), default=-1),\n",
    "    max((max(items, default=-1) for items in test_dict.values()), default=-1)\n",
    ") + 1\n",
    "\n",
    "print('Number of users: %d, Number of items: %d' % (user_num, item_num))\n",
    "\n",
    "# Prepare training, validation, and test data\n",
    "\n",
    "train_data = [[int(user), int(item)] for user, items in train_dict.items() for item in items]\n",
    "valid_gt = [[int(user), int(item)] for user, items in valid_dict.items() for item in items]\n",
    "test_gt = [[int(user), int(item)] for user, items in test_dict.items() for item in items]\n",
    "print('Training samples: %d, Validation samples: %d, Test samples: %d' % (len(train_data), len(valid_gt), len(test_gt)))\n",
    "\n",
    "# Load item features\n",
    "\n",
    "category_feature_size = len(category_features)\n",
    "unique_categories = set(category_features.values())\n",
    "category_encoder = OneHotEncoder()\n",
    "category_encoder.fit(np.array(list(unique_categories)).reshape(-1, 1))\n",
    "category_features_onehot = category_encoder.transform(np.array(list(category_features.values())).reshape(-1, 1)).toarray()\n",
    "print('Category features shape: %s' % str(category_features_onehot.shape))\n",
    "\n",
    "visual_feature_size = len(visual_features)\n",
    "example_key = next(iter(visual_features.keys()))\n",
    "print('Visual features shape: %s' % str(visual_features[example_key].shape))\n",
    "\n",
    "# Create user profiles\n",
    "\n",
    "def create_user_profiles(interaction_dict, category_features, visual_features):\n",
    "\n",
    "    user_profiles = {\n",
    "        user_id: {\n",
    "            'category_sum': np.zeros(category_features_onehot.shape[1]), \n",
    "            'visual_sum': np.zeros(visual_features[0].shape),\n",
    "            'count': 0\n",
    "        }\n",
    "        for user_id in interaction_dict\n",
    "    }\n",
    "\n",
    "    for user_id, items in interaction_dict.items():\n",
    "        for item_id in items:\n",
    "            user_profiles[user_id]['category_sum'] += category_features[item_id]\n",
    "            user_profiles[user_id]['visual_sum'] += visual_features[item_id]\n",
    "            user_profiles[user_id]['count'] += 1\n",
    "\n",
    "    # Averaging the features for each user profile\n",
    "    for profile in user_profiles.values():\n",
    "        if profile['count'] > 0:\n",
    "            profile['category_sum'] /= profile['count']\n",
    "            profile['visual_sum'] /= profile['count']\n",
    "\n",
    "    return user_profiles\n",
    "\n",
    "train_user_profiles = create_user_profiles(train_dict, category_features_onehot, visual_features)\n",
    "valid_user_profiles = create_user_profiles(valid_dict, category_features_onehot, visual_features)\n",
    "test_user_profiles = create_user_profiles(test_dict, category_features_onehot, visual_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedModel(nn.Module):\n",
    "    def __init__(self, num_categories, num_visual_features, hidden_dim):\n",
    "        super(ContentBasedModel, self).__init__()\n",
    "        # User category pathway\n",
    "        self.model_name = 'ContentBasedModel'\n",
    "        self.user_category_fc = nn.Linear(num_categories, hidden_dim)\n",
    "        \n",
    "        # Item category pathway\n",
    "        self.item_category_fc = nn.Linear(num_categories, hidden_dim)\n",
    "        \n",
    "        # User visual pathway\n",
    "        self.user_visual_fc = nn.Linear(num_visual_features, hidden_dim)\n",
    "        \n",
    "        # Item visual pathway\n",
    "        self.item_visual_fc = nn.Linear(num_visual_features, hidden_dim)\n",
    "        \n",
    "        # Combined features for prediction\n",
    "        self.combined_fc = nn.Linear(hidden_dim * 4, hidden_dim)  # *4 because we concatenate user+item category+visual features\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user_category, user_visual, item_category, item_visual):\n",
    "        # Process features through respective pathways\n",
    "        user_category_out = F.relu(self.user_category_fc(user_category))\n",
    "        item_category_out = F.relu(self.item_category_fc(item_category))\n",
    "        user_visual_out = F.relu(self.user_visual_fc(user_visual))\n",
    "        item_visual_out = F.relu(self.item_visual_fc(item_visual))\n",
    "        \n",
    "        # Combine all pathways\n",
    "        combined_features = torch.cat((user_category_out, item_category_out, user_visual_out, item_visual_out), dim=1)\n",
    "        \n",
    "        # Further processing for final prediction\n",
    "        combined_out = F.relu(self.combined_fc(combined_features))\n",
    "        output = torch.sigmoid(self.output_layer(combined_out))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise parameters\n",
    "\n",
    "seed = 4242\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_num_threads(torch.get_num_threads())\n",
    "\n",
    "data_path = \"../data/\"\n",
    "model = \"MF\"\n",
    "emb_size = 100\n",
    "lr = 0.001\n",
    "dropout = 0.0\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "device = \"cpu\"\n",
    "top_k = [10, 20, 50, 100]\n",
    "log_name = \"log\"\n",
    "model_path = \"./models/\"\n",
    "num_categories = 368\n",
    "num_visual_features = 512\n",
    "embedding_dim = 32\n",
    "hidden_dim = 32\n",
    "diversity_param = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "train_dataset = CBFData(\n",
    "    user_item_pairs=train_data, \n",
    "    num_items=item_num, \n",
    "    category_features=category_features_onehot,\n",
    "    visual_features=visual_features,\n",
    "    user_profiles=train_user_profiles, \n",
    "    train_dict=train_dict, \n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diversity(recommended_categories):\n",
    "    K = len(recommended_categories)\n",
    "    diversity_score = 0\n",
    "    \n",
    "    for i in range(K):\n",
    "        for j in range(i+1, K):\n",
    "            if recommended_categories[i] != recommended_categories[j]:\n",
    "                diversity_score += 1\n",
    "\n",
    "    # Normalize by the number of possible pairs\n",
    "    diversity_score /= (K * (K - 1) / 2.0)\n",
    "    return diversity_score\n",
    "\n",
    "# Function to calculate the F1 score for diversity and relevance\n",
    "def f1_score(ndcg_score, ild_score):\n",
    "    if not np.isnan(ndcg_score) and not np.isnan(ild_score):  \n",
    "        f1 = 2 * (ndcg_score * ild_score) / (ndcg_score + ild_score)\n",
    "    else:\n",
    "        f1 = 0  \n",
    "    return f1\n",
    "\n",
    "def rerank_for_diversity(initial_recommendations, item_categories, diversity_param):\n",
    "    reranked_items = []\n",
    "    category_penalty = {}  # Dictionary to keep track of category penalties\n",
    "\n",
    "    for item_id, score in initial_recommendations:\n",
    "        category = item_categories[item_id]\n",
    "        penalty = category_penalty.get(category, 0) # Get penalty for this category\n",
    "        diversity_score = score * (1 - diversity_param) - penalty * diversity_param \n",
    "        reranked_items.append((item_id, diversity_score))\n",
    "        category_penalty[category] = category_penalty.get(category, 0) + 1 # Update category penalty to 1\n",
    "\n",
    "    # Sort items by diversity_score\n",
    "    reranked_items.sort(key=lambda x: x[1], reverse=True)\n",
    "    reranked_item_ids = [item_id for item_id, _ in reranked_items]\n",
    "\n",
    "    return reranked_item_ids\n",
    "\n",
    "def evaluate_cbf(model, top_k, train_dict, gt_dict, user_profiles, category_features, category_features_one_hot, visual_features, device, diversity_param, is_training):\n",
    "    recommends = {k: [] for k in top_k}\n",
    "    diversity_scores = {k: [] for k in top_k}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_id, true_items in gt_dict.items():\n",
    "            if not true_items:  \n",
    "                continue\n",
    "            '''\n",
    "            if model.model_name == 'CBF':\n",
    "                user_category = torch.tensor(user_profiles[user_id]['category_sum'], dtype=torch.float32).unsqueeze(0)\n",
    "                user_visual = torch.tensor(user_profiles[user_id]['visual_sum'], dtype=torch.float32).unsqueeze(0)\n",
    "                interacted_items = train_dict[user_id] if user_id in train_dict else []\n",
    "                item_ids = [i for i in range(len(category_features_one_hot)) if i not in interacted_items]\n",
    "                item_category_tensor = torch.stack([torch.tensor(category_features_one_hot[i], dtype=torch.float32) for i in item_ids])\n",
    "                item_visual_tensor = torch.stack([torch.tensor(visual_features[i], dtype=torch.float32) for i in item_ids])\n",
    "                scores = model(user_category.repeat(len(item_ids), 1), user_visual.repeat(len(item_ids), 1), item_category_tensor, item_visual_tensor).squeeze()\n",
    "            '''\n",
    "            for user_id, true_items in gt_dict.items(): # Iterate over all users\n",
    "                scores = np.zeros(len(category_features)) # Initialize scores for all items\n",
    "\n",
    "                user_category = torch.tensor(user_profiles[user_id]['category_sum'], dtype=torch.float32).unsqueeze(0).to(device) # Get user profile\n",
    "                user_visual = torch.tensor(user_profiles[user_id]['visual_sum'], dtype=torch.float32).unsqueeze(0).to(device) # Get user profile\n",
    "                \n",
    "                item_ids = [i for i in range(len(category_features)) if i not in train_dict.get(user_id, [])]\n",
    "                for item_id in item_ids:\n",
    "\n",
    "                    item_category = torch.tensor(category_features_one_hot[item_id], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                    item_visual = torch.tensor(visual_features[item_id], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                    # Score the user-item pair\n",
    "                    score = model(user_category, user_visual, item_category, item_visual).squeeze().cpu().numpy()\n",
    "                    scores[item_id] = score\n",
    "                \n",
    "                # Exclude scores for training items by setting them to -inf\n",
    "                scores[list(train_dict.get(user_id, []))] = -np.inf\n",
    "                # scores = torch.tensor(scores, dtype=torch.float32).to(device)\n",
    "            \n",
    "                \n",
    "\n",
    "            # Generate recommendation pool for reranking\n",
    "            # recommendation_pool_size = max(top_k) * 5\n",
    "            # top_scores, top_indices = torch.topk(scores, recommendation_pool_size)\n",
    "            # recommendation_pool = [(item_ids[i], scores[i].item()) for i in top_indices.cpu().numpy()]\n",
    "\n",
    "            for k in top_k:\n",
    "                # top_k_items = np.argsort(scores)[-k:]\n",
    "                initial_recommendations = np.argsort(scores)[-k:]\n",
    "                print('Initial Recommendations', initial_recommendations)\n",
    "                final_recommendations = []\n",
    "\n",
    "                if not is_training and diversity_param > 0:\n",
    "                    rerank_input = [(item_id, score) for item_id, score in initial_recommendations]\n",
    "                    final_recommendations = rerank_for_diversity(rerank_input, {i: category_features[i] for i, _ in rerank_input}, diversity_param)\n",
    "                else:\n",
    "                    final_recommendations = [item_id for item_id, _ in initial_recommendations]\n",
    "                \n",
    "                print('Final Recommendations', final_recommendations)\n",
    "\n",
    "                # Compute ild_score based on final recommendations\n",
    "                final_categories = [category_features[item_id] for item_id in final_recommendations]\n",
    "                ild_score = calculate_diversity(final_categories)\n",
    "\n",
    "                # Store the final recommendations and their diversity score\n",
    "                recommends[k].append(final_recommendations)\n",
    "                diversity_scores[k].append(ild_score)\n",
    "\n",
    "    print('Recommendations', recommends)\n",
    "    print('Diversity Scores', diversity_scores)\n",
    "\n",
    "    return recommends, diversity_scores\n",
    "\n",
    "def metrics_cbf(model, top_k, train_dict, gt_dict, user_profiles, category_features, category_features_one_hot, visual_features, device, diversity_param=0.5, is_training=True):\n",
    "    \n",
    "    recommends, diversity_scores = evaluate_cbf(model, top_k, train_dict, gt_dict, user_profiles, category_features, category_features_one_hot, visual_features, device, diversity_param, is_training)\n",
    "\n",
    "    results = {} \n",
    "    \n",
    "    for k in top_k:\n",
    "        sumForRecall, sumForNDCG, user_length = 0, 0, 0 # Initialize variables for average calculation\n",
    "        user_ids_list = list(gt_dict.keys())  # Ensure we have a consistent order\n",
    "        \n",
    "        for idx, user_id in enumerate(user_ids_list):\n",
    "            true_items = gt_dict[user_id]\n",
    "            if len(true_items) == 0:\n",
    "                continue  # Skip users with no ground truth data\n",
    "            \n",
    "            if idx >= len(recommends[k]):  # Guard against index out of bounds\n",
    "                continue\n",
    "            \n",
    "            recommended_items = recommends[k][idx]  # Access by index\n",
    "            userhit, dcg, idcg = 0, 0, 0\n",
    "            idcgCount = len(true_items)\n",
    "            \n",
    "            for index, item in enumerate(recommended_items[:k]):\n",
    "                if item in true_items:\n",
    "                    userhit += 1\n",
    "                    dcg += 1.0 / np.log2(index + 2)\n",
    "                if idcgCount > 0:\n",
    "                    idcg += 1.0 / np.log2(index + 2)\n",
    "                    idcgCount -= 1\n",
    "            \n",
    "            ndcg = dcg / idcg if idcg != 0 else 0\n",
    "            recall = userhit / len(true_items) if len(true_items) > 0 else 0\n",
    "            \n",
    "            sumForRecall += recall\n",
    "            sumForNDCG += ndcg\n",
    "            user_length += 1\n",
    "        \n",
    "        avg_recall = sumForRecall / user_length if user_length > 0 else 0\n",
    "        avg_ndcg = sumForNDCG / user_length if user_length > 0 else 0\n",
    "        avg_ild = np.mean([diversity_scores[k]]) if k in diversity_scores and diversity_scores[k] else 0\n",
    "        avg_f1 = np.mean([f1_score(avg_ndcg, avg_ild)])\n",
    "\n",
    "        results[k] = {'Recall': avg_recall, 'NDCG': avg_ndcg, 'ILD': avg_ild, 'F1': avg_f1}\n",
    "        print(f\"Top-{k}: Avg Recall: {avg_recall:.4f}, Avg NDCG: {avg_ndcg:.4f}, Avg ILD: {avg_ild:.4f}, Avg F1 Score: {avg_f1:.4f}\")\n",
    "    \n",
    "    return recommends, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluate_CBF(model, user_profiles, category_features, visual_features, gt_dict, train_dict, device, top_k=(10, 20, 50, 100)):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "\n",
    "    # No need to prepare these tensors in advance since we'll process each item individually\n",
    "    with torch.no_grad():\n",
    "        for K in top_k:\n",
    "            recall_sum = 0.0\n",
    "            ndcg_sum = 0.0\n",
    "            num_users = len(gt_dict)\n",
    "\n",
    "            for user_id, true_items in gt_dict.items():\n",
    "                scores = np.zeros(len(category_features))\n",
    "\n",
    "                user_category = torch.tensor(user_profiles[user_id]['category_sum'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                user_visual = torch.tensor(user_profiles[user_id]['visual_sum'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                \n",
    "                for item_id in range(len(category_features)):\n",
    "                    # Skip items the user has seen in training\n",
    "                    if item_id in train_dict.get(user_id, []):\n",
    "                        continue\n",
    "\n",
    "                    item_category = torch.tensor(category_features[item_id], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                    item_visual = torch.tensor(visual_features[item_id], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                    # Score the user-item pair\n",
    "                    score = model(user_category, user_visual, item_category, item_visual).squeeze().cpu().numpy()\n",
    "                    scores[item_id] = score\n",
    "                \n",
    "                # Exclude scores for training items by setting them to -inf\n",
    "                scores[list(train_dict.get(user_id, []))] = -np.inf\n",
    "\n",
    "                # Get top-K items based on scores\n",
    "                top_k_items = np.argsort(scores)[-K:]\n",
    "                \n",
    "                # Calculate metrics\n",
    "                num_hits = len(set(top_k_items) & set(true_items))\n",
    "                recall = num_hits / float(len(true_items))\n",
    "                recall_sum += recall\n",
    "\n",
    "                ndcg = calculate_ndcg(top_k_items, true_items, K)\n",
    "                ndcg_sum += ndcg\n",
    "            \n",
    "            recalls.append(recall_sum / num_users)\n",
    "            ndcgs.append(ndcg_sum / num_users)\n",
    "\n",
    "    return recalls, ndcgs\n",
    "\n",
    "def calculate_ndcg(predicted_items, true_items, K):\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    for i, pred in enumerate(predicted_items[-K:]):\n",
    "        if pred in true_items:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    for i in range(min(len(true_items), K)):\n",
    "        idcg += 1.0 / np.log2(i + 2)\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6876490488648415, Time elapsed: 28.66s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6l/xwrqvy7n1814gqhygtglkblw0000gn/T/ipykernel_23600/3515185556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mrecommends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_cbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_user_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mfirst_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6l/xwrqvy7n1814gqhygtglkblw0000gn/T/ipykernel_23600/1013188946.py\u001b[0m in \u001b[0;36mmetrics_cbf\u001b[0;34m(model, top_k, train_dict, gt_dict, user_profiles, category_features, category_features_one_hot, visual_features, device, diversity_param, is_training)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmetrics_cbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mrecommends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_cbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6l/xwrqvy7n1814gqhygtglkblw0000gn/T/ipykernel_23600/1013188946.py\u001b[0m in \u001b[0;36mevaluate_cbf\u001b[0;34m(model, top_k, train_dict, gt_dict, user_profiles, category_features, category_features_one_hot, visual_features, device, diversity_param, is_training)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mrecommendation_pool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtop_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendation_pool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mrecommendation_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6l/xwrqvy7n1814gqhygtglkblw0000gn/T/ipykernel_23600/1013188946.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mrecommendation_pool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtop_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommendation_pool_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mrecommendation_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the model\n",
    "\n",
    "model = ContentBasedModel(num_categories, num_visual_features, hidden_dim)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_f1_score = 0\n",
    "best_recall = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        user_category, user_visual, item_category, item_visual, labels = batch\n",
    "        user_category, user_visual = user_category.to(device), user_visual.to(device)\n",
    "        item_category, item_visual = item_category.to(device), item_visual.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_category, user_visual, item_category, item_visual).squeeze()\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Time elapsed: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    # Evaluation    \n",
    "    recommends, results = metrics_cbf(model, top_k, train_dict, valid_dict, train_user_profiles, category_features, category_features_onehot, visual_features, device, diversity_param, is_training=True)\n",
    "\n",
    "    first_k = top_k[0]\n",
    "\n",
    "    # Update best F1 score and save model if necessary based on the first k value\n",
    "    current_best_f1 = results[first_k]['F1']\n",
    "    current_best_recall = results[first_k]['Recall']\n",
    "    if current_best_recall > best_recall:\n",
    "        best_recall = current_best_recall\n",
    "        best_f1 = current_best_f1\n",
    "        # Save the model checkpoint\n",
    "        torch.save(model.state_dict(), f'./models/best_model_{model.model_name}.pth')\n",
    "        print(f\"New best model saved with Recall: {best_recall}, F1: {best_f1}, model path: ./models/best_model_{model.model_name}.pth\")\n",
    "    print('---'*18)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(\"Best Recall: \", best_recall)\n",
    "print(\"Best F1 score: \", best_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "\n",
    "model = ContentBasedModel(num_categories, num_visual_features, hidden_dim)\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "recalls, ndcgs = evaluate_CBF(model, test_user_profiles, category_features_onehot, visual_features, test_dict, train_dict, device, top_k=[10, 20, 50, 100])\n",
    "print(f\"[Test] Recall: {recalls}, NDCG: {ndcgs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
