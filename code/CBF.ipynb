{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import data_utils\n",
    "import model as model\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "train_dict = np.load('../data/training_dict.npy', allow_pickle=True).item()\n",
    "valid_dict = np.load('../data/validation_dict.npy', allow_pickle=True).item()\n",
    "test_dict = np.load('../data/testing_dict.npy', allow_pickle=True).item()\n",
    "category_features = np.load(os.path.join('../data/category_feature.npy'), allow_pickle=True).item()\n",
    "visual_features = np.load(os.path.join('../data/visual_feature.npy'), allow_pickle=True).item()\n",
    "\n",
    "# Get the number of users and items\n",
    "\n",
    "user_num = max(max(train_dict), max(valid_dict, default=-1), max(test_dict, default=-1)) + 1\n",
    "\n",
    "item_num = max(\n",
    "    max((max(items, default=-1) for items in train_dict.values()), default=-1),\n",
    "    max((max(items, default=-1) for items in valid_dict.values()), default=-1),\n",
    "    max((max(items, default=-1) for items in test_dict.values()), default=-1)\n",
    ") + 1\n",
    "\n",
    "print('Number of users: %d, Number of items: %d' % (user_num, item_num))\n",
    "\n",
    "# Prepare training, validation, and test data\n",
    "\n",
    "train_data = [[int(user), int(item)] for user, items in train_dict.items() for item in items]\n",
    "valid_gt = [[int(user), int(item)] for user, items in valid_dict.items() for item in items]\n",
    "test_gt = [[int(user), int(item)] for user, items in test_dict.items() for item in items]\n",
    "print('Training samples: %d, Validation samples: %d, Test samples: %d' % (len(train_data), len(valid_gt), len(test_gt)))\n",
    "\n",
    "# Load item features\n",
    "\n",
    "category_feature_size = len(category_features)\n",
    "unique_categories = set(category_features.values())\n",
    "category_encoder = OneHotEncoder()\n",
    "category_encoder.fit(np.array(list(unique_categories)).reshape(-1, 1))\n",
    "category_features_onehot = category_encoder.transform(np.array(list(category_features.values())).reshape(-1, 1)).toarray()\n",
    "print('Category features shape: %s' % str(category_features_onehot.shape))\n",
    "\n",
    "visual_feature_size = len(visual_features)\n",
    "example_key = next(iter(visual_features.keys()))\n",
    "print('Visual features shape: %s' % str(visual_features[example_key].shape))\n",
    "\n",
    "# Create user profiles\n",
    "\n",
    "def create_user_profiles(interaction_dict, category_features, visual_features):\n",
    "\n",
    "    user_profiles = {\n",
    "        user_id: {\n",
    "            'category_sum': np.zeros(category_features_onehot.shape[1]), \n",
    "            'visual_sum': np.zeros(visual_features[0].shape),\n",
    "            'count': 0\n",
    "        }\n",
    "        for user_id in interaction_dict\n",
    "    }\n",
    "\n",
    "    for user_id, items in interaction_dict.items():\n",
    "        for item_id in items:\n",
    "            user_profiles[user_id]['category_sum'] += category_features[item_id]\n",
    "            user_profiles[user_id]['visual_sum'] += visual_features[item_id]\n",
    "            user_profiles[user_id]['count'] += 1\n",
    "\n",
    "    # Averaging the features for each user profile\n",
    "    for profile in user_profiles.values():\n",
    "        if profile['count'] > 0:\n",
    "            profile['category_sum'] /= profile['count']\n",
    "            profile['visual_sum'] /= profile['count']\n",
    "\n",
    "    return user_profiles\n",
    "\n",
    "train_user_profiles = create_user_profiles(train_dict, category_features_onehot, visual_features)\n",
    "valid_user_profiles = create_user_profiles(valid_dict, category_features_onehot, visual_features)\n",
    "test_user_profiles = create_user_profiles(test_dict, category_features_onehot, visual_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedModel(nn.Module):\n",
    "    def __init__(self, num_categories, num_visual_features, hidden_dim):\n",
    "        super(ContentBasedModel, self).__init__()\n",
    "        # User category pathway\n",
    "        self.user_category_fc = nn.Linear(num_categories, hidden_dim)\n",
    "        \n",
    "        # Item category pathway\n",
    "        self.item_category_fc = nn.Linear(num_categories, hidden_dim)\n",
    "        \n",
    "        # User visual pathway\n",
    "        self.user_visual_fc = nn.Linear(num_visual_features, hidden_dim)\n",
    "        \n",
    "        # Item visual pathway\n",
    "        self.item_visual_fc = nn.Linear(num_visual_features, hidden_dim)\n",
    "        \n",
    "        # Combined features for prediction\n",
    "        self.combined_fc = nn.Linear(hidden_dim * 4, hidden_dim)  # *4 because we concatenate user+item category+visual features\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, user_category, user_visual, item_category, item_visual):\n",
    "        # Process features through respective pathways\n",
    "        user_category_out = F.relu(self.user_category_fc(user_category))\n",
    "        item_category_out = F.relu(self.item_category_fc(item_category))\n",
    "        user_visual_out = F.relu(self.user_visual_fc(user_visual))\n",
    "        item_visual_out = F.relu(self.item_visual_fc(item_visual))\n",
    "        \n",
    "        # Combine all pathways\n",
    "        combined_features = torch.cat((user_category_out, item_category_out, user_visual_out, item_visual_out), dim=1)\n",
    "        \n",
    "        # Further processing for final prediction\n",
    "        combined_out = F.relu(self.combined_fc(combined_features))\n",
    "        output = torch.sigmoid(self.output_layer(combined_out))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise parameters\n",
    "\n",
    "seed = 4242\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_num_threads(torch.get_num_threads())\n",
    "\n",
    "data_path = \"../data/\"\n",
    "model = \"MF\"\n",
    "emb_size = 100\n",
    "lr = 0.001\n",
    "dropout = 0.0\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "device = \"cpu\"\n",
    "top_k = [10, 20, 50, 100]\n",
    "log_name = \"log\"\n",
    "model_path = \"./models/\"\n",
    "num_categories = 368\n",
    "num_visual_features = 512\n",
    "embedding_dim = 32\n",
    "hidden_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "train_dataset = data_utils.CBFData(\n",
    "    user_item_pairs=train_data, \n",
    "    num_items=item_num, \n",
    "    category_features=category_features_onehot,\n",
    "    visual_features=visual_features,\n",
    "    user_profiles=train_user_profiles, \n",
    "    train_dict=train_dict, \n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluate_CBF(model, user_profiles, category_features, visual_features, gt_dict, train_dict, device, top_k=(10, 20, 50, 100)):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "\n",
    "    # No need to prepare these tensors in advance since we'll process each item individually\n",
    "    with torch.no_grad():\n",
    "        for K in top_k:\n",
    "            recall_sum = 0.0\n",
    "            ndcg_sum = 0.0\n",
    "            num_users = len(gt_dict)\n",
    "\n",
    "            for user_id, true_items in gt_dict.items():\n",
    "                scores = np.zeros(len(category_features))\n",
    "\n",
    "                user_category = torch.tensor(user_profiles[user_id]['category_sum'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                user_visual = torch.tensor(user_profiles[user_id]['visual_sum'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                \n",
    "                for item_id in range(len(category_features)):\n",
    "                    # Skip items the user has seen in training\n",
    "                    if item_id in train_dict.get(user_id, []):\n",
    "                        continue\n",
    "\n",
    "                    item_category = torch.tensor(category_features[item_id], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "                    item_visual = torch.tensor(visual_features[item_id], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                    # Score the user-item pair\n",
    "                    score = model(user_category, user_visual, item_category, item_visual).squeeze().cpu().numpy()\n",
    "                    scores[item_id] = score\n",
    "                \n",
    "                # Exclude scores for training items by setting them to -inf\n",
    "                scores[list(train_dict.get(user_id, []))] = -np.inf\n",
    "\n",
    "                # Get top-K items based on scores\n",
    "                top_k_items = np.argsort(scores)[-K:]\n",
    "                \n",
    "                # Calculate metrics\n",
    "                num_hits = len(set(top_k_items) & set(true_items))\n",
    "                recall = num_hits / float(len(true_items))\n",
    "                recall_sum += recall\n",
    "\n",
    "                ndcg = calculate_ndcg(top_k_items, true_items, K)\n",
    "                ndcg_sum += ndcg\n",
    "            \n",
    "            recalls.append(recall_sum / num_users)\n",
    "            ndcgs.append(ndcg_sum / num_users)\n",
    "\n",
    "    return recalls, ndcgs\n",
    "\n",
    "def calculate_ndcg(predicted_items, true_items, K):\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    for i, pred in enumerate(predicted_items[-K:]):\n",
    "        if pred in true_items:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    for i in range(min(len(true_items), K)):\n",
    "        idcg += 1.0 / np.log2(i + 2)\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training the model\n",
    "\n",
    "model = ContentBasedModel(num_categories, num_visual_features, hidden_dim)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_recall = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        user_category, user_visual, item_category, item_visual, labels = batch\n",
    "        user_category, user_visual = user_category.to(device), user_visual.to(device)\n",
    "        item_category, item_visual = item_category.to(device), item_visual.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_category, user_visual, item_category, item_visual).squeeze()\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Evaluation\n",
    "    recalls, ndcgs = evaluate_CBF(model, valid_user_profiles, category_features_onehot, visual_features, valid_dict, train_dict, device, top_k=[10, 20, 50, 100])\n",
    "    print(f\"[Validation] Recall: {recalls}, NDCG: {ndcgs}\")\n",
    "\n",
    "    # Update best recall and save model if necessary\n",
    "    current_best_recall = max(recalls)\n",
    "    if current_best_recall > best_recall:\n",
    "        best_recall = current_best_recall\n",
    "        # Save the model checkpoint\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"New best model saved with recall: {best_recall}\")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "\n",
    "model = ContentBasedModel(num_categories, num_visual_features, hidden_dim)\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "recalls, ndcgs = evaluate_CBF(model, test_user_profiles, category_features_onehot, visual_features, test_dict, train_dict, device, top_k=[10, 20, 50, 100])\n",
    "print(f\"[Test] Recall: {recalls}, NDCG: {ndcgs}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
