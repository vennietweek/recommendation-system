{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from data_utils import *\n",
    "from evaluate_cbf import *\n",
    "from models import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise parameters\n",
    "\n",
    "seed = 4242\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_num_threads(torch.get_num_threads())\n",
    "\n",
    "emb_size = 100\n",
    "lr = 0.001\n",
    "dropout = 0.0\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "device = \"cpu\"\n",
    "top_k = [10, 20, 50, 100]\n",
    "log_name = \"log\"\n",
    "model_path = \"./models/\"\n",
    "num_categories = 368\n",
    "num_visual_features = 512\n",
    "embedding_dim = 32\n",
    "hidden_dim = 32\n",
    "diversity_param = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 506, Number of items: 1674\n",
      "Training samples: 12358, Validation samples: 406, Test samples: 406\n",
      "Category features shape: (1674, 368)\n",
      "Visual features shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "user_num, item_num, train_dict, valid_dict, test_dict, train_data, valid_gt, test_gt, category_features_onehot, visual_features, train_user_profiles, valid_user_profiles, test_user_profiles = load_data()\n",
    "\n",
    "# Create training dataset\n",
    "train_dataset = CBFData(user_item_pairs=train_data, num_items=item_num, category_features=category_features_onehot, visual_features=visual_features, user_profiles=train_user_profiles, train_dict=train_dict, is_training=True)\n",
    "\n",
    "# Create dataloader object\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Epoch 1, Loss: 0.6849391037417997, Time elapsed: 28.57s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6l/xwrqvy7n1814gqhygtglkblw0000gn/T/ipykernel_52909/4175666234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mrecommends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_ndcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_ild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_user_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Metrics - F1: {f1_scores}, NDCG: {ndcg_scores}, ILD: {diversity_scores}, Recall: {recall_scores}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/4242project/code/evaluate_cbf.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(model, top_k, train_dict, gt_dict, user_profiles, category_features, visual_features, device, diversity_param, is_training)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mrecommends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_profiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mf1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/4242project/code/evaluate_cbf.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, top_k, train_dict, gt_dict, user_profiles, category_features, visual_features, device, diversity_param, is_training)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Convert item features to tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mitem_category_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mitem_visual_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m# Compute scores for all items in a single batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not dict"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the model\n",
    "\n",
    "model = ContentBasedModel(num_categories, num_visual_features, hidden_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "best_f1_score = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        user_category, user_visual, item_category, item_visual, labels = batch\n",
    "        user_category, user_visual = user_category.to(device), user_visual.to(device)\n",
    "        item_category, item_visual = item_category.to(device), item_visual.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_category, user_visual, item_category, item_visual).squeeze()\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print('---'*18)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Time elapsed: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    # Evaluation    \n",
    "    recommends, avg_f1, avg_ndcg, avg_ild, avg_recall, f1_scores, ndcg_scores, diversity_scores, recall_scores = metrics(model, top_k, train_dict, valid_dict, train_user_profiles, category_features_onehot, visual_features, device, diversity_param, is_training=True)\n",
    "    print(f\"Validation Metrics - F1: {f1_scores}, NDCG: {ndcg_scores}, ILD: {diversity_scores}, Recall: {recall_scores}\")\n",
    "\n",
    "    # Update best F1 score and save model if necessary\n",
    "    current_best_f1 = max(f1_scores)\n",
    "    if current_best_f1 > best_f1_score:\n",
    "        best_f1_score = current_best_f1\n",
    "        # Save the model checkpoint\n",
    "        torch.save(model.state_dict(), '/models/best_model/{time.time()}.pth')\n",
    "        print(f\"New best model saved with F1 score: {best_f1_score}, model path: best_model/{time.time()}.pth\")\n",
    "    print('---'*18)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(\"Best F1 score: \", best_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "model = ContentBasedModel(num_categories, num_visual_features, hidden_dim)\n",
    "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "recommends, avg_f1, avg_ndcg, avg_ild, avg_recall, f1_scores, ndcg_scores, diversity_scores, recall_scores = metrics(model, top_k, train_dict, test_dict, test_user_profiles, category_features_onehot, visual_features, device, diversity_param, is_training=False)\n",
    "print(f\"Test Metrics - F1: {f1_scores}, NDCG: {ndcg_scores}, ILD: {diversity_scores}, Recall: {recall_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
